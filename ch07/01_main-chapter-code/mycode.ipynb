{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-26T06:02:46.432477Z",
     "start_time": "2025-11-26T06:02:46.380012Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.21.5\n",
      "matplotlib version: 3.5.1\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0+cu126\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.19.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:07:54.514268Z",
     "start_time": "2025-11-26T05:07:54.505291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ],
   "id": "1d216dc865df832a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:08:08.287134Z",
     "start_time": "2025-11-26T05:08:08.283893Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Example entry:\\n\", data[50])",
   "id": "eceb711aa9f3c7b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:08:16.144547Z",
     "start_time": "2025-11-26T05:08:16.141383Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Another example entry:\\n\", data[999])",
   "id": "3e71f30a89e04f38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:08:35.409905Z",
     "start_time": "2025-11-26T05:08:35.406531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "id": "e74f007c7c8ae4e0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:09:08.429892Z",
     "start_time": "2025-11-26T05:09:08.426636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ],
   "id": "6f169ff8743056",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:09:13.192276Z",
     "start_time": "2025-11-26T05:09:13.188350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ],
   "id": "8b9ca17379f0a9c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:09:21.173290Z",
     "start_time": "2025-11-26T05:09:21.169841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ],
   "id": "d0de28857401cd4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:09:28.073453Z",
     "start_time": "2025-11-26T05:09:28.069730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ],
   "id": "5a07ce0a5c0f270d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:09:40.224033Z",
     "start_time": "2025-11-26T05:09:40.219804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "id": "4d6d4b2ec1a5670a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:09:51.575738Z",
     "start_time": "2025-11-26T05:09:51.154734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "id": "c0f55e9dede673e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:10:21.986926Z",
     "start_time": "2025-11-26T05:10:21.982966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ],
   "id": "b067266a7d4bad2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:11:32.426892Z",
     "start_time": "2025-11-26T05:11:32.422800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ],
   "id": "410cd2fcbd089826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:11:33.339301Z",
     "start_time": "2025-11-26T05:11:33.335554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "95abcec6818a9c6e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:12:00.127694Z",
     "start_time": "2025-11-26T05:12:00.123291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "id": "5cc44c941a2e7164",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:12:11.654257Z",
     "start_time": "2025-11-26T05:12:11.649975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "360cc6ba8a75829a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:12:16.961805Z",
     "start_time": "2025-11-26T05:12:16.931118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "id": "cfa066ec4dc4298e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:16:45.644277Z",
     "start_time": "2025-11-26T05:16:45.429513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ],
   "id": "6ce64b11079418e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:17:03.982980Z",
     "start_time": "2025-11-26T05:17:03.978610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ],
   "id": "4bb3e25e9860dd33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:17:23.304201Z",
     "start_time": "2025-11-26T05:17:23.299752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ],
   "id": "18e4b8dea4d6dcde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:18:36.272501Z",
     "start_time": "2025-11-26T05:18:36.265399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    # Use PyTorch 2.9 or newer for stable mps results\n",
    "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
    "    if (major, minor) >= (2, 9):\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ],
   "id": "aa9cdede30365f24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:18:40.221273Z",
     "start_time": "2025-11-26T05:18:40.218424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ],
   "id": "1f93286902377d94",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:18:45.269215Z",
     "start_time": "2025-11-26T05:18:45.214491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "id": "af68011030c81cf8",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:18:50.986270Z",
     "start_time": "2025-11-26T05:18:50.977877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "id": "6fc626a6316a7113",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:18:54.802820Z",
     "start_time": "2025-11-26T05:18:54.717075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ],
   "id": "65f0441a16a370a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:19:12.397790Z",
     "start_time": "2025-11-26T05:19:12.394267Z"
    }
   },
   "cell_type": "code",
   "source": "print(inputs[0])",
   "id": "29fec42100580001",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:19:21.092756Z",
     "start_time": "2025-11-26T05:19:21.089042Z"
    }
   },
   "cell_type": "code",
   "source": "print(targets[0])",
   "id": "b7e0cdedf2574ba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:27:32.435526Z",
     "start_time": "2025-11-26T05:27:15.977058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"../../ch05/01_main-chapter-code/gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ],
   "id": "4852bedfa34e677d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: ../../ch05/01_main-chapter-code/gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:27:32.458841Z",
     "start_time": "2025-11-26T05:27:32.444478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ],
   "id": "c7ebd2b0cc7cac16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:27:45.543310Z",
     "start_time": "2025-11-26T05:27:42.384303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ],
   "id": "d5e090e85a060c2a",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:28:25.023404Z",
     "start_time": "2025-11-26T05:28:25.020120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ],
   "id": "ade2868fd25f407a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:28:27.108805Z",
     "start_time": "2025-11-26T05:28:27.106087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ],
   "id": "4ed99c298c1f2791",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:28:33.572811Z",
     "start_time": "2025-11-26T05:28:28.562402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "68d691bf7d48b8a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.1671370506286625\n",
      "Validation loss: 4.050931739807129\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:41:25.716601Z",
     "start_time": "2025-11-26T05:28:35.242231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "id": "a50fa37e5a8c4131",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.069\n",
      "Ep 1 (Step 000005): Train loss 1.696, Val loss 1.570\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.164\n",
      "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.083\n",
      "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.038\n",
      "Ep 1 (Step 000025): Train loss 0.920, Val loss 1.002\n",
      "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.978\n",
      "Ep 1 (Step 000035): Train loss 0.877, Val loss 0.951\n",
      "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.943\n",
      "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.925\n",
      "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.911\n",
      "Ep 1 (Step 000055): Train loss 0.923, Val loss 0.893\n",
      "Ep 1 (Step 000060): Train loss 0.872, Val loss 0.877\n",
      "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.867\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.860\n",
      "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.855\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.847\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.836\n",
      "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.827\n",
      "Ep 1 (Step 000095): Train loss 0.652, Val loss 0.821\n",
      "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.808\n",
      "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.803\n",
      "Ep 1 (Step 000110): Train loss 0.718, Val loss 0.799\n",
      "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.796\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is an instruction that describes a task.\n",
      "Ep 2 (Step 000120): Train loss 0.592, Val loss 0.790\n",
      "Ep 2 (Step 000125): Train loss 0.626, Val loss 0.801\n",
      "Ep 2 (Step 000130): Train loss 0.583, Val loss 0.789\n",
      "Ep 2 (Step 000135): Train loss 0.547, Val loss 0.791\n",
      "Ep 2 (Step 000140): Train loss 0.579, Val loss 0.789\n",
      "Ep 2 (Step 000145): Train loss 0.518, Val loss 0.785\n",
      "Ep 2 (Step 000150): Train loss 0.520, Val loss 0.780\n",
      "Ep 2 (Step 000155): Train loss 0.594, Val loss 0.784\n",
      "Ep 2 (Step 000160): Train loss 0.585, Val loss 0.785\n",
      "Ep 2 (Step 000165): Train loss 0.537, Val loss 0.781\n",
      "Ep 2 (Step 000170): Train loss 0.440, Val loss 0.775\n",
      "Ep 2 (Step 000175): Train loss 0.479, Val loss 0.769\n",
      "Ep 2 (Step 000180): Train loss 0.540, Val loss 0.760\n",
      "Ep 2 (Step 000185): Train loss 0.567, Val loss 0.757\n",
      "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.742\n",
      "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.729\n",
      "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.728\n",
      "Ep 2 (Step 000205): Train loss 0.479, Val loss 0.724\n",
      "Ep 2 (Step 000210): Train loss 0.516, Val loss 0.725\n",
      "Ep 2 (Step 000215): Train loss 0.539, Val loss 0.734\n",
      "Ep 2 (Step 000220): Train loss 0.413, Val loss 0.738\n",
      "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.738\n",
      "Ep 2 (Step 000230): Train loss 0.425, Val loss 0.742\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical symbol for carbon?  \n",
      "Training completed in 12.84 minutes.\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:41:27.431666Z",
     "start_time": "2025-11-26T05:41:25.747009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "9b3ea7839da3b3c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:49:00.462810Z",
     "start_time": "2025-11-26T05:48:55.952428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ],
   "id": "a98f3ee5a8596042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:51:46.509396Z",
     "start_time": "2025-11-26T05:49:02.183691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ],
   "id": "ca15e41ba36add53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [02:44<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:52:11.752437Z",
     "start_time": "2025-11-26T05:52:11.749257Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_data[0])",
   "id": "5ab24695909498c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a horse.'}\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:52:16.991348Z",
     "start_time": "2025-11-26T05:52:14.584937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n"
   ],
   "id": "df7a564e8f32db37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T06:18:09.114577Z",
     "start_time": "2025-11-26T06:18:09.081339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psutil\n",
    "\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"ollama\"))"
   ],
   "id": "3ff51eaab8887220",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T06:18:12.197926Z",
     "start_time": "2025-11-26T06:18:12.159286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "id": "216742d1ff075bc7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T06:03:33.398662Z",
     "start_time": "2025-11-26T06:03:27.846588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests  # noqa: F811\n",
    "# import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    # If you used OLLAMA_HOST=127.0.0.1:11435 ollama serve\n",
    "    # update the address from 11434 to 11435\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    with requests.post(url, json=data, stream=True, timeout=30) as r:\n",
    "        r.raise_for_status()\n",
    "        response_data = \"\"\n",
    "        for line in r.iter_lines(decode_unicode=True):\n",
    "            if not line:\n",
    "                continue\n",
    "            response_json = json.loads(line)\n",
    "            if \"message\" in response_json:\n",
    "                response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data\n",
    "\n",
    "\n",
    "model = \"deepseek-r1:1.5b\"\n",
    "result = query_model(\"What do Llamas eat?\", model)\n",
    "print(result)"
   ],
   "id": "b93ba307ee0f08c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Llamas are large, gray animals that are native to the wild and are often found in the United States. They are not typically raised for eating other animals but are primarily used as grazing animals. However, some studies suggest that llamas can consume a variety of plants, including grasses, cacti, and certain types of shrubs. These plants may be part of their diet or serve as food sources during the winter months when they are less active.\n",
      "\n",
      "It's important to note that llamas are generally not known for eating other animals in large quantities, but some research has shown that they can eat small amounts of other species, particularly at night.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T05:58:37.442833Z",
     "start_time": "2025-11-26T05:58:27.209055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ],
   "id": "eb195a4400b9ec0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "\n",
      "Score:\n",
      ">> <think>\n",
      "Okay, so I need to figure out how to rewrite the sentence \"The car is very fast\" using a simile. The user provided an example response which was \"The car is as fast as lightning,\" and scored it with a 95/100. Hmm, that's pretty good. But maybe there are other ways to express this.\n",
      "\n",
      "First, I should understand what a simile is. A simile is a figure of speech that compares two things using similar but not identical qualities. So, instead of saying \"the car is very fast,\" I need to find another way to compare it to something else that's also described with a quality.\n",
      "\n",
      "The example used lightning because it's a common and vivid image for speed. Maybe other words could work too. Let me think about other things that are known for being fast or quick. For instance, \"as lightning\" is good, but maybe \"as a cheetah\" would be another option since cheetahs are known for their speed.\n",
      "\n",
      "Wait, the user's example used \"lightning,\" which is a strong simile. Maybe I can think of other strong similes. How about \"as a bird\"? Birds can fly really fast, so that could work too. Or maybe \"as a rocket\" because rockets are very fast and have high speeds.\n",
      "\n",
      "I should also consider the context. Is this sentence part of a larger instruction or task? The user didn't specify, but since they just provided the instruction to rewrite using a simile, I can assume it's standalone. So, any simile that effectively conveys speed would be appropriate.\n",
      "\n",
      "Let me think about other words. \"As lightning\" is strong because lightning is so fast and unpredictable. \"As a cheetah\" might also work because cheetahs are known for their agility. Alternatively, \"as a cheetah\" could be another good choice.\n",
      "\n",
      "Wait, the user's example used \"lightning,\" which is more vivid than \"chicken.\" So maybe I should stick with something that's as vivid or strong as lightning. But if I can find another word that's equally effective, that would be better.\n",
      "\n",
      "Another thought: \"as a cheetah\" might not be the best because it's a bit of a stretch in terms of speed compared to other animals. Maybe \"as a cheetah\" is still acceptable since it's commonly associated with speed and agility.\n",
      "\n",
      "Alternatively, I could use \"as lightning\" again, but that's already used. So maybe \"as a cheetah\" or \"as a cheetah.\" Or perhaps \"as a cheetah\" isn't the best because it might not be as widely known as lightning.\n",
      "\n",
      "Wait, another option: \"as lightning\" is good, but if I can find something else that's even more vivid. Maybe \"as lightning\" is better than \"as a cheetah.\"\n",
      "\n",
      "I think I'll go with \"The car is as fast as lightning.\" That's the example given and it's effective because lightning is so fast and is a strong simile.\n",
      "\n",
      "But just to be thorough, let me consider other possibilities. How about \"as a cheetah\" or \"as a cheetah\"? Or maybe \"as a cheetah\" again? Alternatively, \"as lightning\" is the best choice here.\n",
      "</think>\n",
      "\n",
      "The car is as fast as lightning.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "\n",
      "Score:\n",
      ">> <think>\n",
      "Okay, so I need to figure out what type of cloud is typically associated with thunderstorms. Let me start by recalling some basic meteorological concepts.\n",
      "\n",
      "I know that clouds are composed of various particles suspended in the atmosphere, and they can be classified into different types based on their characteristics. Thunderstorms involve a lot of rain or lightning, so I'm thinking about clouds that produce such weather conditions.\n",
      "\n",
      "First, I remember that cumulonimbus clouds are a type of large cloud. They're often associated with thunderstorms because they have the potential to cause heavy rainfall. But wait, is it just any cumulonimbus cloud? Or is there more specific classification?\n",
      "\n",
      "I think there's a distinction between cumulonimbus and cumulus clouds. Cumulus clouds include things like cumulus lendolytes (rain droplets) and cumulus th stems (snowflakes). These are smaller clouds that can lead to rain or snow, which might not be directly associated with thunderstorms as much.\n",
      "\n",
      "On the other hand, cumulonimbus clouds are larger and more likely to produce significant weather events. They include cumulonimbus clouds themselves, which are often referred to as \"tropical\" in some contexts because they're part of the tropical climate system. So, if a cloud is classified as a cumulonimbus cloud, it's specifically tied to thunderstorms.\n",
      "\n",
      "I also recall that cumulonimbus clouds can have different types based on their height and structure. For example, there are cumulonimbus torricelli, which are tall and narrow, and others like cumulonimbus katabatic, which are found in the tropics and often associated with thunderstorms due to their high altitude.\n",
      "\n",
      "So putting it all together, a cloud typically associated with thunderstorms is most likely a cumulonimbus cloud. It's not just any large cloud but specifically one that can lead to significant rainfall or lightning events.\n",
      "</think>\n",
      "\n",
      "The type of cloud typically associated with thunderstorms is **cumulonimbus**.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "\n",
      "Score:\n",
      ">> <think>\n",
      "Okay, so I need to figure out how to respond to this user's query about identifying the author of \"Pride and Prejudice.\" The instruction given was straightforward: name the author and correct the output if it's wrong. But then the user provided a different response where they said the author is Robert Frost instead of Jane Austen, which I know is incorrect.\n",
      "\n",
      "Hmm, that seems like a mistake. I remember that \"Pride and Prejudice\" is by Jane Austen, not Robert Frost. Maybe the user confused the two authors or thought one was more famous than the other. I should correct this response to ensure accuracy.\n",
      "\n",
      "I wonder why someone would think it's Robert Frost. Perhaps they're mixing up the works of Austen with others like Emma Donoghue or maybe even someone else. It's important to clarify that the title is associated with a specific author, so Jane Austen is definitely the one here.\n",
      "\n",
      "Also, considering the user's request was about correctness and accuracy, I should make sure my response is clear and confident in providing the right information. Maybe they're testing if I can recognize common mistakes or perhaps trying to engage by pointing out an error in their knowledge.\n",
      "\n",
      "I think it's best to acknowledge their correction and provide the accurate answer. That way, they learn from their mistake and understand that sometimes even experts make errors. So, my response should be straightforward: name Jane Austen and give a high score for accuracy.\n",
      "</think>\n",
      "\n",
      "The author of 'Pride and Prejudice' is Jane Austen. Score: 95.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T06:17:37.291972Z",
     "start_time": "2025-11-26T06:17:36.902774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"deepseek-r1:1.5b\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ],
   "id": "ec6bef4c751a0c75",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 21\u001B[0m\n\u001B[0;32m     16\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scores\n\u001B[1;32m---> 21\u001B[0m scores \u001B[38;5;241m=\u001B[39m generate_model_scores(\u001B[43mtest_data\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_response\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of scores: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(scores)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(test_data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAverage score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(scores)\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mlen\u001B[39m(scores)\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tellme",
   "language": "python",
   "name": "tellme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
